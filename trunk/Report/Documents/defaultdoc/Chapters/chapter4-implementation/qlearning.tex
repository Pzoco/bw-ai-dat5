\newpage

\section{$ \hat{Q}$-Learning}

In this section we'll address the implementation of the Reinforcement Learning Approximation. First we'll explain the $ReinforcementLearning$ class and the methods that calculate the value of the $\hat{Q}$ function and updating rules. Then the necessary calculations made throughout the game to create the data needed in order to use this class and save the relevant information for testing.\nolinebreak

\subsection{ReinforcementLearning Class}

This class contains all the variables and processes necessary to calculate all the formulas of the $\hat{Q} learning$. It is used throughout the game to update each coefficient of the $\hat{Q}_f$ function, calculate the reward for each state-action pair, calculate the different values of the $\hat{Q}$ itself and saving all the necessary data to continue the calculations in the next iteration of the game (also for saving a data log with all the numbers for further analysis and testing).

\subsubsection{Field Summary}

\begin{centering}
 \begin{tabular}{|l|p {10cm}|}
 	\hline
 	double const  &  $alpha$\linebreak  The $\alpha$ value of the $\hat{Q}_f$ function updating rules. \\
 	\hline
 	double const &  $gamma$ \linebreak The $\gamma$ value of the $\hat{Q}_f$ function updating rules. \\
 	\hline
 	double const  &  $startingEnemies$\linebreak  Number of enemy units (manual input).\\
 	\hline
 	double const  &  $startingEnemyMaxHealth$\linebreak  Maximum Enemy Health (manual input).\\
 	\hline
 	double const  &  $startingUnits$\linebreak  Number of units (manual input).\\
 	\hline
 	double const  &  $startingUnitMaxHealth$\linebreak  Maximum Health (manual input).\\
 	\hline
 	double const  &  $c1$\linebreak  Reward function's $C_1$ value, set to -180, coefficient for the number of units. \\
 	\hline
 	double const  &  $c2$\linebreak  Reward function's $C_2$ value, set to -1, coefficient for the amount of health lost.\\
 	\hline
 	double const  &  $c3$\linebreak  Reward function's $C_3$ value, set to 2, coefficient for the damage dealt. \\
 	\hline
 	double const  &  $c4$\linebreak  Reward function's $C_4$ value, set to 40, coefficient for the number of kills.\\
 	\hline
 	double const  &  $c5$\linebreak  Reward function's $C_5$ value, set to -0.025, coefficient for the frame count inside a game (time).\\
 	\hline
 	double[ ] &  $liveBuffer$\linebreak  Array used for saving the different $\hat{Q}_f$ updating values, its purpose is to optimize the test d data saving (to files) to only a few occurrences throughout the game. \\
 	\hline
 	int &  $liveCount$\linebreak  Counter for controlling the $liveBuffer$.\\
 	\hline
 	struct Weights & \_$weights$\{double FORCEALLY, double FORCESQUAD, double FORCEMAXDIST, double FORCECOOLDOWN, double FORCEEDGE\}\linebreak  Struct used to save all the values of the $f_i$'s in the $\hat{Q}_f$ function throughout all the calculations in the game. \\
 	\hline
\end{tabular}
\end{centering}

%____________________________________________________________________________________________________

\subsubsection{Method Summary}

\begin{centering}
 \begin{tabular}{|l|p {11cm}|}
	
	\hline
	static double & \textbf{CalculateTheta(double theta, double reward, double currQ, double nextQ, double derivative)}\linebreak Returns the value of the updating rule for the current coefficient $f_i$ of the $\hat{Q}_f$ function.\\
	
	\hline
        static double & \textbf{CalculateReward(std::set$<$BWAPI::Unit*$>$squad)}\linebreak Returns the value of the reward function $R(s) = C_1 numberOfUnits  +  C_2 healthLost  +   C_3 damageDealt  +   C_4 numberOfKills 	+  C_5 time$.\\
     
     \hline
        static void & \textbf{LoadWeightsFromFile()}\linebreak Loads the weights ($f$) of the $\hat{Q}_f$ function into the \_\emph{weights} field.\\
	
	\hline
        static void & \textbf{SaveCurrentWeightsToFile()}\linebreak Saves the last weights ($f$) of the $\hat{Q}_f$ function into the weight's file.\\
   
    \hline
       static void & \textbf{WriteLiveValue(double value)}\linebreak Writes a value into the array $liveBuffer$ for future use in the calculations.\\
	
	\hline
        static double* & \textbf{GetLiveBuffer()}\linebreak Returns the $liveBuffer$ array. \\
	
	\hline
        static int & \textbf{GetLiveCount()}\linebreak Returns the $liveCount$ value that indicates how many numbers have been saved in the $liveBuffer$.\\
        
	\hline
        static void & \textbf{ClearLiveBuffer()}\linebreak Clears the current values in the $liveBuffer$ and initializes $liveCount$ to 0.\\
	
	\hline
        static void & \textbf{WriteToDataFiles()}\linebreak Saves game data into files for future analysis. It saves the game count, remaining health, remaining enemy health, remaining squad size, remaining number of enemies. It is only to be used at the end of each game.\\
	
	\hline
        static double & \textbf{GetForceAlly()}\linebreak Returns the value of \_\emph{weights.FORCEALLY}.\\
	
	\hline
        static double & \textbf{GetForceSquad()}\linebreak Returns the value of \_\emph{weights.FORCESQUAD}.\\
	
	\hline
        static double & \textbf{GetForceMaxDist()}\linebreak Returns the value of \_\emph{weights.FORCEMAXDIST}.\\
	
	\hline
        static double & \textbf{GetForceCooldown()}\linebreak Returns the value of \_\emph{weights.FORCECOOLDOWN}.\\
	
	\hline
        static double & \textbf{GetForceEdge()}\linebreak Returns the value of \_\emph{weights.FORCEEDGE}.\\
	
	\hline
        static void & \textbf{SetForceAlly(double ally)}\linebreak Sets the value of \_\emph{weights.FORCEALLY} to $ally$.\\
	
	\hline
        static void & \textbf{SetForceSquad(double squad)}\linebreak Sets the value of \_\emph{weights.FORCESQUAD} to $squad$.\\
	
	\hline
        static void & \textbf{SetForceMaxDist(double mde)}\linebreak Sets the value of \_\emph{weights.FORCEMAXDIST} to $mde$.\\
	
	\hline
        static void & \textbf{SetForceCooldown(double cool)}\linebreak Sets the value of \_\emph{weights.FORCECOOLDOWN} to $cool$.\\
	
	\hline
        static void & \textbf{SetForceEdge(double edge)}\linebreak Sets the value of \_\emph{weights.FORCEEDGE} to $edge$.\\
	
	\hline
\end{tabular}
\end{centering}


%Note that we assign values now to the coefficients of the reward function we designed (link to reward function in design!!!!!!!!!!!!!!!!!!!!!). This values  


\subsubsection{Method Detail}


