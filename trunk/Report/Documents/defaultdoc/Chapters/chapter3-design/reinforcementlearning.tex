\section{Reinforcement Learning}

	Reinforcement learning is a method used to build a model or functions that learn from experience and examples. The basic idea is that for every action in an environment there is a reward or feedback that reinforces all the actions that have bigger rewards. In a bigger scale the task of reinforcement learning is the process to discover the optimal path or series of actions to accomplish the best possible reward at the end of the process. 

	The choice of using reinforcement learning was based on the necessity to train our AI to perform better after every match or test. Since our environment covers a lot of different factors and variables, we then decided on using a form of active reinforcement learning that simplifies the complexity and size of all the different states in the environment: Generalization. 

	Generalization in reinforcement learning takes into consideration huge state spaces by representing them by function approximation. This function reduces the complexity of mapping all the states considerably and allows the learning agent to generalize form the visited states to the not visited ones. 

	We combine the reinforcement learning method with the potential fields by transforming all the potential fields of each unit into the representation of the utility function used by the agent. We do this by talking all the forces that determine the magnitude of the potential field vectors as coefficients in the utility function:

	% There should be something about:
		% Passive Reinforcement / Active Reinforcement
			% Direct utility estimation
			% Adaptive dynamic programming
			% Temporal difference learning
			% Exploration
			% Q-Learning