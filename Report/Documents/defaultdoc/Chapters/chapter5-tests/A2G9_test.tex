%here goes the final converging test of the A2G9 - only the text ofc! - and ref to the picture at F8-11

\subsection*{Convergence for $\alpha= 0.2$ and $\gamma = 0.9$}

By convergence we mean that the agent has found the perfect values that works every time, in other words the agent gets the highest reward. In figure \ref{fig:app_a2g9_test} one can clearly see that the agent tries with different values and after the almost 250.000 iterations it's beginning to narrow down to a more dense line instead of trying higher values. The blue line which says \textit{edge} has a drop way below zero, and that might be a buffer overflow, but if we only look at the \textit{ally} and \textit{squad} we can see that the agent have learned that sticking together in a group is better than attacking marines individually. The \textit{cooldown} is beginning to have a more dense line which means that the agent have learned that when they have fired it's good to flee so they won't get injured. The \textit{maximum distance} is not as high as we expected, since the higher it is the more aggressive the vultures are. Even more iterations could perfect these numbers to a convergence and the vultures would then win every game. 


